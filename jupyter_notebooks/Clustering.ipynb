{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "from scipy.spatial.distance import pdist\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import DBSCAN, KMeans, MeanShift\n",
    "from social_dynamics import autoencoder_utils\n",
    "import tensorflow as tf\n",
    "import utils\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "root_path = utils.determine_root_path()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "autoencoder_clustering_path = root_path.joinpath(\"large_autoencoder_clustering\")\n",
    "autoencoder_results_path = autoencoder_clustering_path.joinpath(\"autoencoders_results\")\n",
    "model_input_types = [\"cnn-complete\", \"cnn-cut\", \"dnn-complete\", \"dnn-cut\"]\n",
    "\n",
    "results = utils.load_autoencoder_exploration_results(path=autoencoder_clustering_path,\n",
    "                                                     model_input_types=model_input_types)\n",
    "\n",
    "series_dir_path = Path(\"/home/htc/fmalerba/experiments_results/2_opt-h_luzie-alpha_beta_gamma_delta_expl-0.0001t\")\n",
    "datasets, n_agents, n_options = autoencoder_utils.load_all_datasets(series_dir=series_dir_path,\n",
    "                                                                    downsampling=4)\n",
    "y_trues = dict([(key, np.array(list(datasets[key].as_numpy_iterator()))[:, 1])\n",
    "                for key in datasets])\n",
    "del datasets"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model_path = autoencoder_results_path.joinpath(\n",
    "    utils.select_autoencoder_model(model_input_type='dnn-cut', results=results, mode='best', start=6, end=7))\n",
    "#model_path = autoencoder_results_path.joinpath('cnn-cut-1')\n",
    "\n",
    "model_input_type = \"-\".join(model_path.name.split('-')[:2])\n",
    "batched_flag = \"batched\" in model_input_type\n",
    "\n",
    "embeddings = np.load(model_path.joinpath(\"embeddings.npy\"))\n",
    "embeddings = np.reshape(embeddings, (embeddings.shape[0], -1))\n",
    "y_pred = np.load(model_path.joinpath(\"predictions.npy\"))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.figure(figsize=(20, 8))\n",
    "plt.hist(pdist(embeddings, metric='euclidean'), bins=200)\n",
    "plt.title(f'Distribution of embedding distances for {model_path.name}')\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# K-Means Clustering"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "n_clusters = 4\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(embeddings)\n",
    "labels = kmeans.labels_\n",
    "one_hot_encodings = tf.one_hot(indices=labels, depth=n_clusters).numpy()\n",
    "pca_plotter = utils.PCAPlotter(X=embeddings, y=one_hot_encodings, classes=[str(i) for i in range(n_clusters)])\n",
    "pca_plotter.plotPCA_3D()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Mean shift Clustering"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mean_shift = MeanShift(bandwidth=1, n_jobs=10).fit(embeddings)\n",
    "labels = mean_shift.labels_\n",
    "unique_labels, counts = np.unique(labels, return_counts=True)\n",
    "n_clusters = unique_labels.size\n",
    "print(n_clusters)\n",
    "print(unique_labels)\n",
    "print(counts/np.sum(counts))\n",
    "one_hot_encodings = tf.one_hot(indices=labels, depth=n_clusters).numpy()\n",
    "if n_clusters <= 5:\n",
    "    pca_plotter = utils.PCAPlotter(X=embeddings, y=one_hot_encodings, classes=[str(i) for i in range(n_clusters)])\n",
    "    pca_plotter.plotPCA_3D()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# DBSCAN Clustering"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dbscan = DBSCAN(eps=6, n_jobs=10).fit(embeddings)\n",
    "labels = dbscan.labels_\n",
    "unique_labels, counts = np.unique(labels, return_counts=True)\n",
    "n_clusters = unique_labels.size\n",
    "print(n_clusters)\n",
    "print(unique_labels)\n",
    "print(counts/np.sum(counts))\n",
    "one_hot_encodings = tf.one_hot(indices=labels, depth=n_clusters).numpy()\n",
    "if n_clusters <= 5:\n",
    "    pca_plotter = utils.PCAPlotter(X=embeddings, y=one_hot_encodings, classes=[str(i) for i in range(n_clusters)])\n",
    "    pca_plotter.plotPCA_3D()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# PCA KMeans Clustering"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "n_clusters = 4\n",
    "pca = PCA(n_components=3)\n",
    "reduced_embeddings = pca.fit_transform(embeddings)\n",
    "\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(reduced_embeddings)\n",
    "labels = kmeans.labels_\n",
    "one_hot_encodings = tf.one_hot(indices=labels, depth=n_clusters).numpy()\n",
    "pca_plotter = utils.PCAPlotter(X=reduced_embeddings, y=one_hot_encodings, classes=[str(i) for i in range(n_clusters)])\n",
    "pca_plotter.plotPCA_3D()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Plot predictions from all clusters"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "n_to_sample = 10\n",
    "\n",
    "fig, axes = plt.subplots(n_to_sample*n_options, 2*n_clusters, figsize=(40, 60), dpi=150)\n",
    "for i in range(n_clusters):\n",
    "    trues, preds = autoencoder_utils.select_predictions(mode='clusters', n_to_sample=n_to_sample, y_true=y_trues[model_input_type],\n",
    "                                                        y_pred=y_pred, clusters=labels, selected_cluster=i)\n",
    "    preds = np.transpose(preds, axes=(0,2,1)) if batched_flag else preds\n",
    "    trues = np.transpose(trues, axes=(0,2,1)) if batched_flag else trues\n",
    "    autoencoder_utils.plot_preds(axes=axes[:, 2*i:2*(i+1)],\n",
    "                                 y_true=trues,\n",
    "                                 y_pred=preds,\n",
    "                                 n_agents=n_agents,\n",
    "                                 n_options=n_options)\n",
    "\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Plot predictions from single cluster"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "trues, preds = autoencoder_utils.select_predictions(mode='clusters', n_to_sample=5, y_true=y_trues[model_input_type],\n",
    "                                                    y_pred=y_pred, clusters=labels, selected_cluster=4)\n",
    "\n",
    "fig, axes = plt.subplots(trues.shape[0]*n_options, 2, figsize=(10, 15))\n",
    "plt.title(model_path.name)\n",
    "autoencoder_utils.plot_preds(axes=axes,\n",
    "                             y_true=trues,\n",
    "                             y_pred=preds,\n",
    "                             n_agents=n_agents,\n",
    "                             n_options=n_options)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "social-dynamics",
   "display_name": "social-dynamics",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}