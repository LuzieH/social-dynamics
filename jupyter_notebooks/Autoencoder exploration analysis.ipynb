{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\r\n",
    "import matplotlib.image as mpimg\r\n",
    "import numpy as np\r\n",
    "import os\r\n",
    "import utils\r\n",
    "\r\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\r\n",
    "\r\n",
    "root_path = utils.determine_root_path()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "autoencoder_clustering_path = root_path.joinpath(\"large_autoencoder_clustering\")\r\n",
    "autoencoder_results_path = autoencoder_clustering_path.joinpath(\"autoencoders_results\")\r\n",
    "model_input_types = [\"cnn-complete\", \"cnn-cut\", \"dnn-complete\", \"dnn-cut\"]\r\n",
    "\r\n",
    "results = utils.load_autoencoder_exploration_results(path=autoencoder_clustering_path,\r\n",
    "                                                     model_input_types=model_input_types)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# MSE Distribution over models"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.figure(figsize=(15, 15))\r\n",
    "for i, model_input_type in enumerate(model_input_types):\r\n",
    "    plt.subplot(4, 1, i+1)\r\n",
    "    plt.hist(results[results[\"Model-Input Type\"] == model_input_type][\"MSE\"], bins=50)\r\n",
    "    plt.xlim(0, 12)\r\n",
    "    plt.xlabel('MSE')\r\n",
    "    plt.ylabel('Frequency')\r\n",
    "    plt.title(model_input_type)\r\n",
    "\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\r\n",
    "plt.figure(figsize=(15, 15))\r\n",
    "for i, model_input_type in enumerate(model_input_types):\r\n",
    "    plt.subplot(4, 1, i+1)\r\n",
    "    mse_results = results[results[\"Model-Input Type\"] == model_input_type][\"MSE\"].values\r\n",
    "    n_params_dist = results[results[\"Model-Input Type\"] == model_input_type][\"N. Params\"].values\r\n",
    "    plt.scatter(n_params_dist, mse_results, s=2)\r\n",
    "    best_model_index = np.argmin(mse_results)\r\n",
    "    plt.scatter(n_params_dist[best_model_index], mse_results[best_model_index], s=20, c='red', label='Best Performer')\r\n",
    "    plt.xlabel('Number of parameters')\r\n",
    "    plt.ylabel('MSE Score')\r\n",
    "    plt.xscale('log')\r\n",
    "    plt.xlim(2*10**5, 1.5*10**9)\r\n",
    "    plt.title(model_input_type + f'      Best model: {best_model_index}')\r\n",
    "    plt.legend()\r\n",
    "\r\n",
    "plt.tight_layout()\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Sample Autoencoder MSE distribution"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model_path = np.random.choice(list(autoencoder_results_path.iterdir()))\r\n",
    "\r\n",
    "plt.figure(figsize=(20, 8))\r\n",
    "plt.hist(np.load(model_path.joinpath('mses.npy')), bins=200)\r\n",
    "plt.title(model_path.name)\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Sample Autoencoder predictions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model_path = np.random.choice(list(autoencoder_results_path.iterdir()))\r\n",
    "\r\n",
    "plt.figure(figsize=(20, 30))\r\n",
    "plt.imshow(mpimg.imread(model_path.joinpath('random_predictions.png')))\r\n",
    "plt.axis('off')\r\n",
    "plt.title(model_path.name)\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Best Models predictions"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "best_results_models = dict([(key, np.argmin(results[key])) for key in results.keys()])\r\n",
    "\r\n",
    "plt.figure(figsize=(40, 60), dpi=150)\r\n",
    "for i, key in enumerate(best_results_models):\r\n",
    "    model_name = key + '-' + str(best_results_models[key])\r\n",
    "    model_path = autoencoder_results_path.joinpath()\r\n",
    "    plt.subplot(1, 4, i + 1)\r\n",
    "    plt.imshow(mpimg.imread(autoencoder_results_path.joinpath(model_name, 'worst_predictions.png')))\r\n",
    "    plt.title(model_name)\r\n",
    "    plt.axis('off')\r\n",
    "\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Autoencoder n_params distribution"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plt.figure(figsize=(15, 15))\r\n",
    "for i, model_input_type in enumerate(model_input_types):\r\n",
    "    plt.subplot(4, 1, i+1)\r\n",
    "    n_params_dist = results[results[\"Model-Input Type\"] == model_input_type][\"N. Params\"].values\r\n",
    "    plt.hist(n_params_dist, bins=50)\r\n",
    "    plt.xscale(\"log\")\r\n",
    "    plt.title(\"{} --- n_models: {} --- mean: {}\".format(model_input_type, n_params_dist.shape[0], format(np.mean(n_params_dist), \"3.2e\")))\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit ('social_dynamics_venv': venv)"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "interpreter": {
   "hash": "e9ae0c68b50dbe7f0857f7e7224d431b77dcd9f0ab924727bcb2969f1e763b2b"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}